---
- name: Security group for WorkerNode
  ec2_group:
    name: Kuberentes-woker-node-SG
    description: Incoming connections to Worker Node
    vpc_id: "{{ vpc_id }}"
    region: "{{ region }}"
    rules:
      - proto: tcp
        ports:
        - 6443
        cidr_ip: 0.0.0.0/0
        rule_desc: API server
      - proto: tcp
        ports:
        - 2379
        - 2380
        cidr_ip: 0.0.0.0/0
        rule_desc: ETCd 
      - proto: tcp
        ports:
        - 22
        cidr_ip: 0.0.0.0/0
        rule_desc: allowing SSH connection
      - proto: tcp
        ports:
        - 10250
        cidr_ip: 0.0.0.0/0
        rule_desc: Kubelet API server
      - proto: tcp
        ports:
        - 10251
        cidr_ip: 0.0.0.0/0
        rule_desc: sheduler
      - proto: tcp
        ports:
        - 10252
        cidr_ip: 0.0.0.0/0
        rule_desc: Controller
      - proto: tcp
        ports:
        - 179
        cidr_ip: 0.0.0.0/0
        rule_desc: Calico required ports
      - proto: udp
        ports:
        - 4789
        cidr_ip: 0.0.0.0/0
        rule_desc: Calico required ports
      - proto: tcp
        ports:
        - 5473
        cidr_ip: 0.0.0.0/0
        rule_desc: Calico required ports
      - proto: tcp
        ports:
        - 4
        cidr_ip: 0.0.0.0/0
        rule_desc: Calico required ports
      - proto: tcp
        ports:
        - 443
        cidr_ip: 0.0.0.0/0
        rule_desc: Calico required ports
  register: __Node_SG

- debug:
    msg: "securtiy groupID is : {{ __Node_SG.group_id }}"

- name: Creating instance for Kubernetes Worker Node
  ec2:
    key_name: "{{ private_key }}"
    group_id: "{{ __Node_SG.group_id }}"
    instance_type: t2.micro
    image: "{{ image_id }}"
    wait: yes
    wait_timeout: 200
    vpc_subnet_id: "{{ subnet_id }}"
    assign_public_ip: yes
    count_tag:
      Name: kubernetes_worker_node
    exact_count: 2
    region: "{{ region }}"
    instance_tags:
        Name: kubernetes_worker_node
  register: __k8_node_IP

- debug:
    var: __k8_node_IP

- set_fact:
    k8_node_01: "{{ __k8_node_IP['instances'][0]['public_ip'] }}"
  when: __k8_node_IP is changed

- set_fact:
    k8_node_01: "{{  __k8_node_IP['tagged_instances'][0]['public_ip']  }}"
  when: __k8_node_IP is not changed

- name: addding ansible group
  add_host:
    name: '{{ k8_node_01 }}'
    groupname: k8_node

- set_fact:
    k8_node_02: "{{ __k8_node_IP['instances'][1]['public_ip'] }}"
  when: __k8_node_IP is changed

- set_fact:
    k8_node_02: "{{  __k8_node_IP['tagged_instances'][1]['public_ip']  }}"
  when: __k8_node_IP is not changed

- name: addding ansible group
  add_host:
    name: '{{ k8_node_02 }}'
    groupname: k8_node


- debug:
    msg: "Ip address of node {{ groups['k8_node'][1] }}"

- name: wait for SSH to come up
  wait_for:
    host: "{{ k8_node_01 }}"
    port: 22
    state: started
